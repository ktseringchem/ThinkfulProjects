{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proposal\n",
    "\n",
    "* <h6>What is the problem you are attempting to solve?</h6>\n",
    "    * Movie reviews are subjective attitudes, emotions and opinions of people and a sentiment extracts information from these reviews. This sentiment analysis will neatly categorize people's sentiment as positive, negative or neutral and provide a topic summary. \n",
    "\n",
    "\n",
    "* <h6>How is your solution valuable?</h6>\n",
    "    * Movie rating doesn't capture the nuances of the opinions and no one wants to sit and read thousands of reviews. These insights can be used to business decisions such as direct marketing, recommendation system, future project directions.\n",
    "    \n",
    "\n",
    "* <h6>What is your data source and how will you access it?</h6>\n",
    "\t* IMDb movie reviews, using scrapy web scraper.\n",
    "    \n",
    "\n",
    "* <h6>What techniques from the course do you anticipate using?</h6>\n",
    "\t* Web scraping (scrapy): to get the data\n",
    "\t* Natural language processing (spaCy): to process the data and to create features \n",
    "\t* word2vec (Continuous Bag of Words): converting words to vectors\n",
    "\t* Neural Network: to analyze the data\n",
    "\n",
    "\n",
    "* <h6>What do you expect to be the biggest challenge youâ€™ll face?</h6>\n",
    "\t* Web scraping is new to me and it seems you need some understanding of web development.\n",
    "\t* Feature creation: sentence negation, sarcasm, terseness, language ambiguity, slang, misspellings, and many others make this task very challenging.\n",
    "\t* Neural Network optimization: adjusting hyperparameters\n",
    "    * Evaluating results: first stragey is to compare it to existing ratings.\n",
    "\n",
    "\n",
    "\n",
    "Problem Description: \n",
    "* What is the problem that you will be investigating? Why is it interesting?\n",
    "* Data: What data will you use? If you are collecting new datasets, how do you plan to collect them?\n",
    "* Methodology/Algorithm: What method or algorithm are you proposing? If there are existing implementations, will you use them and how? How do you plan to improve or modify such implementations?\n",
    "* Related Work: What reading will you examine to provide context and background?\n",
    "* Evaluation Plan: How will you evaluate your results? Qualitatively, what kind of results do you expect (e.g. plots or figures)? Quantitatively, what kind of analysis will you use to evaluate and/or compare your results (e.g. what performance metrics or statistical tests)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* What is the problem that you will be investigating? Why is it interesting?\n",
    "<p style=\"font-family:Helvetica Neue;font-size:20px\"> Movie reviews are subjective attitudes, emotions and opinions of people and a sentiment analysis extracts these information from the reviews. This sentiment analysis will neatly categorize people's sentiment as positive, negative or neutral and provide a topic summary.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ktser\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "\n",
    "#Optimizaton\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# gensim modules\n",
    "import gensim\n",
    "from gensim import utils\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "from gensim.models import Word2Vec, Doc2Vec\n",
    "\n",
    "#string maluplation\n",
    "import re\n",
    "\n",
    "# random\n",
    "from random import shuffle\n",
    "\n",
    "# Beautiful soup is the best way to remove html tags form paragraphs.\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.corpus import stopwords\n",
    "import spacy\n",
    "nlp = spacy.load('en')\n",
    "\n",
    "#plot liberiry\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "#classifiers\n",
    "import sklearn\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#Evaluater\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the data\n",
    "\n",
    "<p style=\"font-family:Helvetica Neue;font-size:20px\">This dataset contains 50,000 reviews split evenly into a 25k train and 25k test sets, and each review is in individual files. The overall distribution of labels is balanced (25k pos and 25k neg), and those were divided into two folders named pos and neg. This data was collected by  Christopher Potts in 2011 and I used all of it for training by model and collected my own data from IMBd, using scraper called scrapy, of a new movie for testing purposes.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0  type                                             review label  \\\n",
      "0           0  test  Once again Mr. Costner has dragged out a movie...   neg   \n",
      "1           1  test  This is an example of why the majority of acti...   neg   \n",
      "2           2  test  First of all I hate those moronic rappers, who...   neg   \n",
      "3           3  test  Not even the Beatles could write songs everyon...   neg   \n",
      "4           4  test  Brass pictures (movies is not a fitting word f...   neg   \n",
      "\n",
      "          file  \n",
      "0      0_2.txt  \n",
      "1  10000_4.txt  \n",
      "2  10001_1.txt  \n",
      "3  10002_3.txt  \n",
      "4  10003_3.txt  \n"
     ]
    }
   ],
   "source": [
    "data_df = pd.read_csv(\"imdb_master.csv\", encoding='ISO-8859-1')\n",
    "print(data_df.head())\n",
    "data = data_df['review']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning the review text\n",
    "\n",
    "<p style=\"font-family:Helvetica Neue;font-size:20px\">Put all the data in a pandas data frame from the individual files and assign sentiment based on the folder the files are in.  Clean the data using Regular expression operations (re), beautiful soup, NLTK and python functions. Since we need to capture the contextual meaning of words and documents, when cleaning the data I need to be careful not to remove too much so as to lose the contextual meaning.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert a raw review to a string of words\n",
    "# The input is a single string (a raw movie review), and \n",
    "# the output is a single string (a preprocessed movie review)\n",
    "    \n",
    "def review_to_words( raw_review ):\n",
    "    #Beautiful soup is the best way to remove HTML tags form paragraphs.\n",
    "    review_text = BeautifulSoup(raw_review, \"lxml\").get_text() \n",
    "    \n",
    "    #Remove everything but the char after ^   \n",
    "    letters_only = re.sub(\"[^a-zA-Z],.\", \" \", review_text) \n",
    "    \n",
    "    #Convert to lower case, split into individual words\n",
    "    words = letters_only.lower().split()\n",
    "    \n",
    "    #Join the words back into one string separated by space, and return the result.\n",
    "    return(words)\n",
    "\n",
    "\n",
    "\n",
    "#In Python, searching a set is much faster than searching a list, so convert the stop words to a set\n",
    "#stops = set(stopwords.words(\"english\"))                  \n",
    "# Remove stop words (this may not be helpful for this project)\n",
    "#meaningful_words = [w for w in words if not w in stops] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP processed each review\n",
    "<p style=\"font-family:Helvetica Neue;font-size:20px\">NLP tokenenizes tex, meaning it segments the text into individual words and annotations, and returns iterable processed Doc with all the information of the original text.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-family:Helvetica Neue;font-size:20px\">Using this to creat list of review list</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Cleaning the text data, apply review_to_words() function created above to raw review data\n",
    "clean_review = []\n",
    "for review in data:\n",
    "    clean_review.append(review_to_words(review))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parsing the review so to make each review a list of word to pass into Word2Vec\n",
    "clean_review_vocab = []\n",
    "for review in clean_review:\n",
    "    review = [token.lemma_ for token in review]\n",
    "    clean_review_vocab.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>type</th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0_2.txt</td>\n",
       "      <td>test</td>\n",
       "      <td>[once, again, mr., costner, has, dragged, out,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10000_4.txt</td>\n",
       "      <td>test</td>\n",
       "      <td>[this, is, an, example, of, why, the, majority...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10001_1.txt</td>\n",
       "      <td>test</td>\n",
       "      <td>[first, of, all, i, hate, those, moronic, rapp...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10002_3.txt</td>\n",
       "      <td>test</td>\n",
       "      <td>[not, even, the, beatles, could, write, songs,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10003_3.txt</td>\n",
       "      <td>test</td>\n",
       "      <td>[brass, pictures, (movies, is, not, a, fitting...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          file  type                                             review  label\n",
       "0      0_2.txt  test  [once, again, mr., costner, has, dragged, out,...      0\n",
       "1  10000_4.txt  test  [this, is, an, example, of, why, the, majority...      0\n",
       "2  10001_1.txt  test  [first, of, all, i, hate, those, moronic, rapp...      0\n",
       "3  10002_3.txt  test  [not, even, the, beatles, could, write, songs,...      0\n",
       "4  10003_3.txt  test  [brass, pictures, (movies, is, not, a, fitting...      0"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#list of words in the model\n",
    "vect_df = pd.DataFrame()\n",
    "vect_df['file'] = data_df['file']\n",
    "vect_df['type'] = data_df['type']\n",
    "vect_df['review'] = clean_review\n",
    "vect_df['label'] = data_df['label']\n",
    "sent_value = {'label': {'neg': 0, 'unsup': 2, 'pos': 1}}\n",
    "vect_df.replace(sent_value, inplace=True)\n",
    "vect_df.to_csv( \"NLPprossReview.csv\", index=False)\n",
    "vect_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics\n",
    "wordperReview = []\n",
    "for x in vect_df['review']:\n",
    "    wordperReview.append(len(x))\n",
    "    \n",
    "reviewstd = statistics.stdev(wordperReview)\n",
    "reviewmean = np.mean(wordperReview)\n",
    "\n",
    "print(len(wordperReview))\n",
    "vect_df['reviewlgth'] = [((x-reviewmean)/reviewstd) for x in wordperReview]\n",
    "vect_df.to_csv( \"NLPprossReview.csv\", index=False)\n",
    "vect_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect_df1 = pd.read_csv(\"NLPprossReview.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = model.wv.vocab.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2Vec\n",
    "\n",
    "* Methodology/Algorithm: What method or algorithm are you proposing? If there are existing implementations, will you use them and how? How do you plan to improve or modify such implementations?\n",
    "\n",
    "<p style=\"font-family:Helvetica Neue;font-size:20px\">The meat of this project is a shallow neural network called word2vec. Word2vec is a two-layer neural network that takes in text and outputs their vectors, so it is a vectorizer. The key difference between word2vec and the other vectorizer (e.g. tfidf, frequency, one-hot-encoder) is the word embading, which says somthing about the relation between the words probabilistically. Other vectorizers lose the ordering of the words and they also ignore semantics of the words because words' vectors are equidistance from each other. Word2Vec expects sentences and each sentnce is a list of words.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = Word2Vec(\n",
    "    clean_review,\n",
    "    workers=4,     # Number of threads to run in parallel (if your computer does parallel processing).\n",
    "    min_count=10,  # Minimum word count threshold.\n",
    "    window=6,      # Number of words around target word to consider.\n",
    "    sg=0,          # Use CBOW because our corpus is small.\n",
    "    sample=1e-3 ,  # Penalize frequent words.\n",
    "    size=300,      # Word vector length.\n",
    "    hs=1           # Use hierarchical softmax.\n",
    ")\n",
    "\n",
    "#can save the model for continued training later or load and use later\n",
    "model.save(\"word2vec.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.466682</td>\n",
       "      <td>0.597939</td>\n",
       "      <td>-0.711605</td>\n",
       "      <td>-0.547824</td>\n",
       "      <td>-0.514286</td>\n",
       "      <td>0.250280</td>\n",
       "      <td>0.132427</td>\n",
       "      <td>-0.386994</td>\n",
       "      <td>0.239543</td>\n",
       "      <td>0.950446</td>\n",
       "      <td>...</td>\n",
       "      <td>0.209242</td>\n",
       "      <td>-0.287189</td>\n",
       "      <td>0.321836</td>\n",
       "      <td>0.146357</td>\n",
       "      <td>-0.513084</td>\n",
       "      <td>0.542753</td>\n",
       "      <td>0.020738</td>\n",
       "      <td>-0.354295</td>\n",
       "      <td>0.097838</td>\n",
       "      <td>once</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.430535</td>\n",
       "      <td>-0.139280</td>\n",
       "      <td>-0.609174</td>\n",
       "      <td>-1.256559</td>\n",
       "      <td>0.655581</td>\n",
       "      <td>0.366726</td>\n",
       "      <td>-0.088082</td>\n",
       "      <td>0.190875</td>\n",
       "      <td>0.702666</td>\n",
       "      <td>0.244045</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.324063</td>\n",
       "      <td>0.291641</td>\n",
       "      <td>0.799045</td>\n",
       "      <td>0.321807</td>\n",
       "      <td>0.991806</td>\n",
       "      <td>0.072002</td>\n",
       "      <td>-0.002257</td>\n",
       "      <td>-1.309535</td>\n",
       "      <td>-0.476252</td>\n",
       "      <td>again</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 301 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.466682  0.597939 -0.711605 -0.547824 -0.514286  0.250280  0.132427   \n",
       "1  1.430535 -0.139280 -0.609174 -1.256559  0.655581  0.366726 -0.088082   \n",
       "\n",
       "          7         8         9  ...         291       292       293  \\\n",
       "0 -0.386994  0.239543  0.950446  ...    0.209242 -0.287189  0.321836   \n",
       "1  0.190875  0.702666  0.244045  ...   -0.324063  0.291641  0.799045   \n",
       "\n",
       "        294       295       296       297       298       299  words  \n",
       "0  0.146357 -0.513084  0.542753  0.020738 -0.354295  0.097838   once  \n",
       "1  0.321807  0.991806  0.072002 -0.002257 -1.309535 -0.476252  again  \n",
       "\n",
       "[2 rows x 301 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Examin the build model\n",
    "vocab = model.wv.vocab.keys()\n",
    "vocab_df = pd.DataFrame(model.wv.vectors)\n",
    "vocab_df['words'] = vocab\n",
    "vocab_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the saved model\n",
    "from gensim.models import KeyedVectors\n",
    "model = KeyedVectors.load(\"word2vec.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('wonderful', 0.7530227899551392), ('terrific', 0.7318073511123657), ('fantastic', 0.7208240628242493), ('good', 0.6874746084213257), ('fine', 0.6351935863494873), ('brilliant', 0.6263442039489746), ('great,', 0.6158812642097473), ('superb', 0.6036423444747925), ('excellent', 0.582080602645874), ('top-notch', 0.5528312921524048)]\n"
     ]
    }
   ],
   "source": [
    "print(model.wv.most_similar('great'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "good\n",
      "awesome\n",
      "pleasant\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Karma\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \"\"\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('princess', 0.4177146553993225)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(model.wv.doesnt_match(\"good bad awful terrible\".split()))\n",
    "print(model.wv.doesnt_match(\"awesome bad awful terrible\".split()))\n",
    "print(model.wv.doesnt_match(\"nice pleasant fine excellent\".split()))\n",
    "# Classic test\n",
    "model.most_similar(positive=['woman', 'king'], negative=['man'], topn=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph the result of Word2Vec\n",
    "\n",
    "<p style=\"font-family:Helvetica Neue;font-size:20px\">How good is this vector representation?\n",
    "    <br> show this using graphs\n",
    "    <br> Hey Zack I am having trouble graphing this so I will do it later\n",
    "    <br> moving on to doc2vec</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "tsne = TSNE(n_components=2, verbose=1, perplexity=1000, n_iter=10000)\n",
    "tsne_results = tsne.fit_transform(vocab_df.drop('words',1))\n",
    "\n",
    "df_tsne = pd.DataFrame()\n",
    "df_tsne['x-tsne'] = tsne_results[:,0]\n",
    "df_tsne['y-tsne'] = tsne_results[:,1]\n",
    "\n",
    "vocab_scat = go.Scatter(\n",
    "                        x = df_tsne['x-tsne'],\n",
    "                        y = df_tsne['y-tsne'],\n",
    "                        mode = \"makers\",\n",
    "                        name = \"Vocab_relation\",\n",
    "                        marker = dict(color = \"rgba(16, 112, 2, 0.8)\"),\n",
    "                        text = vocab_df['words'])\n",
    "\n",
    "layout = dict(title = 'Relationship between words',\n",
    "             xaxis = dict(title='tsne0',zeroline=False)\n",
    "             )\n",
    "fig = dict(data=[vocab_scat], layout = layout)\n",
    "plot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build class to take the average of each review vector to represent that review\n",
    "\n",
    "<p style=\"font-family:Helvetica Neue;font-size:20px\">Now that we have vector representation of the words in our corpus, we need to use it to creat vector representation of the documents to pass it into the classifier neurol network. One way to do that is to take the average of the word vectors in the documents and use the averaged word vector to reprsent the documents.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = 300\n",
    "\n",
    "def makeFeatureVec(words, model, num_features):\n",
    "    # Function to average all of the word vectors in a given\n",
    "    # paragraph\n",
    "    #\n",
    "    # Pre-initialize an empty numpy array (for speed)\n",
    "    featureVec = np.zeros((num_features,),dtype=\"float32\")\n",
    "    #\n",
    "    nwords = 0\n",
    "    # \n",
    "    # Index2word is a list that contains the names of the words in \n",
    "    # the model's vocabulary. Convert it to a set, for speed \n",
    "    index2word_set = set(model.wv.index2word)\n",
    "    #\n",
    "    # Loop over each word in the review and, if it is in the model's\n",
    "    # vocaublary, add its feature vector to the total\n",
    "    for word in words:\n",
    "        if word in index2word_set: \n",
    "            nwords = nwords + 1\n",
    "            featureVec = np.add(featureVec,model.wv[word])\n",
    "    # \n",
    "    # Divide the result by the number of words to get the average\n",
    "    featureVec = np.divide(featureVec,nwords)\n",
    "    return featureVec\n",
    "\n",
    "\n",
    "def getAvgFeatureVecs(reviews, model, num_features):\n",
    "    # Given a set of reviews (each one a list of words), calculate \n",
    "    # the average feature vector for each one and return a 2D numpy array \n",
    "    # \n",
    "    # Initialize a counter\n",
    "    counter = 0\n",
    "    # \n",
    "    # Preallocate a 2D numpy array, for speed\n",
    "    reviewFeatureVecs = np.zeros((len(reviews),num_features),dtype=\"float32\")\n",
    "    # \n",
    "    # Loop through the reviews\n",
    "    for review in reviews:\n",
    "       #\n",
    "       # Print a status message every 1000th review\n",
    "       if counter%1000 == 0:\n",
    "           print (\"Review %d of %d\" % (counter, len(reviews)))\n",
    "       # \n",
    "       # Call the function (defined above) that makes average feature vectors\n",
    "       reviewFeatureVecs[counter] = makeFeatureVec(review, model, num_features)\n",
    "       #\n",
    "       # Increment the counter\n",
    "       counter = counter + 1\n",
    "    return reviewFeatureVecs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Average the vector for each review document and used the averaged vector for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creat training and testing datasets\n",
    "allDataVecs = getAvgFeatureVecs(vect_df['review'], model, num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actuallabel</th>\n",
       "      <th>Review</th>\n",
       "      <th>type</th>\n",
       "      <th>fileName</th>\n",
       "      <th>reviewlgth</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>...</th>\n",
       "      <th>290</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>['once', 'again', 'mr.', 'costner', 'has', 'dr...</td>\n",
       "      <td>test</td>\n",
       "      <td>0_2.txt</td>\n",
       "      <td>-0.388052</td>\n",
       "      <td>-0.538728</td>\n",
       "      <td>0.071106</td>\n",
       "      <td>0.311792</td>\n",
       "      <td>-0.679208</td>\n",
       "      <td>-0.355225</td>\n",
       "      <td>...</td>\n",
       "      <td>0.046088</td>\n",
       "      <td>-0.063314</td>\n",
       "      <td>-0.056695</td>\n",
       "      <td>0.174909</td>\n",
       "      <td>-0.279178</td>\n",
       "      <td>-0.093203</td>\n",
       "      <td>0.304465</td>\n",
       "      <td>-0.146528</td>\n",
       "      <td>0.308760</td>\n",
       "      <td>-0.507710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>['this', 'is', 'an', 'example', 'of', 'why', '...</td>\n",
       "      <td>test</td>\n",
       "      <td>10000_4.txt</td>\n",
       "      <td>0.017937</td>\n",
       "      <td>-0.488188</td>\n",
       "      <td>0.034830</td>\n",
       "      <td>0.289578</td>\n",
       "      <td>-0.692977</td>\n",
       "      <td>-0.335200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.052888</td>\n",
       "      <td>-0.044195</td>\n",
       "      <td>-0.068961</td>\n",
       "      <td>0.177566</td>\n",
       "      <td>-0.279586</td>\n",
       "      <td>-0.090004</td>\n",
       "      <td>0.288698</td>\n",
       "      <td>-0.116357</td>\n",
       "      <td>0.282336</td>\n",
       "      <td>-0.485791</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 305 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Actuallabel                                             Review  type  \\\n",
       "0            0  ['once', 'again', 'mr.', 'costner', 'has', 'dr...  test   \n",
       "1            0  ['this', 'is', 'an', 'example', 'of', 'why', '...  test   \n",
       "\n",
       "      fileName  reviewlgth         0         1         2         3         4  \\\n",
       "0      0_2.txt   -0.388052 -0.538728  0.071106  0.311792 -0.679208 -0.355225   \n",
       "1  10000_4.txt    0.017937 -0.488188  0.034830  0.289578 -0.692977 -0.335200   \n",
       "\n",
       "     ...          290       291       292       293       294       295  \\\n",
       "0    ...     0.046088 -0.063314 -0.056695  0.174909 -0.279178 -0.093203   \n",
       "1    ...     0.052888 -0.044195 -0.068961  0.177566 -0.279586 -0.090004   \n",
       "\n",
       "        296       297       298       299  \n",
       "0  0.304465 -0.146528  0.308760 -0.507710  \n",
       "1  0.288698 -0.116357  0.282336 -0.485791  \n",
       "\n",
       "[2 rows x 305 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_v2d_d2v_mlp_result = pd.DataFrame({'Actuallabel': vect_df['label'],\n",
    "                                   'Review': vect_df['review'],\n",
    "                                   'type': vect_df['type'],\n",
    "                                   'fileName': vect_df['file'],\n",
    "                                   'reviewlgth': vect_df['reviewlgth']})\n",
    "allDataVecs_df = pd.DataFrame(allDataVecs)\n",
    "w2v_v2d_d2v_mlp_result = pd.concat([w2v_v2d_d2v_mlp_result, allDataVecs_df], axis=1)\n",
    "\n",
    "w2v_v2d_d2v_mlp_result.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_v2d_d2v_mlp_result.to_csv( \"w2v_v2d_d2v_mlp_result.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_v2d_d2v_mlp_result = pd.read_csv(\"w2v_v2d_d2v_mlp_result.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 305)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Using the new dataframe segment out the train and test \n",
    "train_data = w2v_v2d_d2v_mlp_result[w2v_v2d_d2v_mlp_result.type == 'train']\n",
    "\n",
    "train_data = train_data[train_data.Actuallabel != 2]\n",
    "\n",
    "test_data = w2v_v2d_d2v_mlp_result[w2v_v2d_d2v_mlp_result.type == 'test']\n",
    "\n",
    "test_data = test_data[test_data.Actuallabel != 2]\n",
    "test_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDataVecs = train_data.drop(['Actuallabel', 'Review', 'type', 'fileName', 'reviewlgth'],1)\n",
    "train_sent = train_data['Actuallabel']\n",
    "testDataVecs = test_data.drop(['Actuallabel', 'Review', 'type', 'fileName', 'reviewlgth'],1)\n",
    "test_sent = test_data['Actuallabel']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>290</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.538728</td>\n",
       "      <td>0.071106</td>\n",
       "      <td>0.311792</td>\n",
       "      <td>-0.679208</td>\n",
       "      <td>-0.355225</td>\n",
       "      <td>0.105115</td>\n",
       "      <td>0.416583</td>\n",
       "      <td>0.309348</td>\n",
       "      <td>0.036577</td>\n",
       "      <td>-0.170625</td>\n",
       "      <td>...</td>\n",
       "      <td>0.046088</td>\n",
       "      <td>-0.063314</td>\n",
       "      <td>-0.056695</td>\n",
       "      <td>0.174909</td>\n",
       "      <td>-0.279178</td>\n",
       "      <td>-0.093203</td>\n",
       "      <td>0.304465</td>\n",
       "      <td>-0.146528</td>\n",
       "      <td>0.308760</td>\n",
       "      <td>-0.507710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.488188</td>\n",
       "      <td>0.034830</td>\n",
       "      <td>0.289578</td>\n",
       "      <td>-0.692977</td>\n",
       "      <td>-0.335200</td>\n",
       "      <td>0.097244</td>\n",
       "      <td>0.393367</td>\n",
       "      <td>0.315076</td>\n",
       "      <td>0.044363</td>\n",
       "      <td>-0.137777</td>\n",
       "      <td>...</td>\n",
       "      <td>0.052888</td>\n",
       "      <td>-0.044195</td>\n",
       "      <td>-0.068961</td>\n",
       "      <td>0.177566</td>\n",
       "      <td>-0.279586</td>\n",
       "      <td>-0.090004</td>\n",
       "      <td>0.288699</td>\n",
       "      <td>-0.116357</td>\n",
       "      <td>0.282336</td>\n",
       "      <td>-0.485791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.500578</td>\n",
       "      <td>0.037942</td>\n",
       "      <td>0.288457</td>\n",
       "      <td>-0.682658</td>\n",
       "      <td>-0.345800</td>\n",
       "      <td>0.093151</td>\n",
       "      <td>0.416503</td>\n",
       "      <td>0.308059</td>\n",
       "      <td>0.033776</td>\n",
       "      <td>-0.137783</td>\n",
       "      <td>...</td>\n",
       "      <td>0.037736</td>\n",
       "      <td>-0.042929</td>\n",
       "      <td>-0.067033</td>\n",
       "      <td>0.193854</td>\n",
       "      <td>-0.275070</td>\n",
       "      <td>-0.083573</td>\n",
       "      <td>0.291871</td>\n",
       "      <td>-0.119588</td>\n",
       "      <td>0.284721</td>\n",
       "      <td>-0.480852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.506992</td>\n",
       "      <td>0.064600</td>\n",
       "      <td>0.288691</td>\n",
       "      <td>-0.667881</td>\n",
       "      <td>-0.334566</td>\n",
       "      <td>0.110343</td>\n",
       "      <td>0.420408</td>\n",
       "      <td>0.312626</td>\n",
       "      <td>-0.032864</td>\n",
       "      <td>-0.145818</td>\n",
       "      <td>...</td>\n",
       "      <td>0.076813</td>\n",
       "      <td>-0.062836</td>\n",
       "      <td>-0.084950</td>\n",
       "      <td>0.234967</td>\n",
       "      <td>-0.267003</td>\n",
       "      <td>-0.111241</td>\n",
       "      <td>0.301085</td>\n",
       "      <td>-0.106685</td>\n",
       "      <td>0.278395</td>\n",
       "      <td>-0.487310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.459814</td>\n",
       "      <td>0.040292</td>\n",
       "      <td>0.257863</td>\n",
       "      <td>-0.662598</td>\n",
       "      <td>-0.310878</td>\n",
       "      <td>0.067216</td>\n",
       "      <td>0.429125</td>\n",
       "      <td>0.326812</td>\n",
       "      <td>-0.003846</td>\n",
       "      <td>-0.134707</td>\n",
       "      <td>...</td>\n",
       "      <td>0.034107</td>\n",
       "      <td>-0.063806</td>\n",
       "      <td>-0.100383</td>\n",
       "      <td>0.213321</td>\n",
       "      <td>-0.256279</td>\n",
       "      <td>-0.078744</td>\n",
       "      <td>0.296476</td>\n",
       "      <td>-0.133884</td>\n",
       "      <td>0.246727</td>\n",
       "      <td>-0.495191</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 300 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0 -0.538728  0.071106  0.311792 -0.679208 -0.355225  0.105115  0.416583   \n",
       "1 -0.488188  0.034830  0.289578 -0.692977 -0.335200  0.097244  0.393367   \n",
       "2 -0.500578  0.037942  0.288457 -0.682658 -0.345800  0.093151  0.416503   \n",
       "3 -0.506992  0.064600  0.288691 -0.667881 -0.334566  0.110343  0.420408   \n",
       "4 -0.459814  0.040292  0.257863 -0.662598 -0.310878  0.067216  0.429125   \n",
       "\n",
       "          7         8         9    ...          290       291       292  \\\n",
       "0  0.309348  0.036577 -0.170625    ...     0.046088 -0.063314 -0.056695   \n",
       "1  0.315076  0.044363 -0.137777    ...     0.052888 -0.044195 -0.068961   \n",
       "2  0.308059  0.033776 -0.137783    ...     0.037736 -0.042929 -0.067033   \n",
       "3  0.312626 -0.032864 -0.145818    ...     0.076813 -0.062836 -0.084950   \n",
       "4  0.326812 -0.003846 -0.134707    ...     0.034107 -0.063806 -0.100383   \n",
       "\n",
       "        293       294       295       296       297       298       299  \n",
       "0  0.174909 -0.279178 -0.093203  0.304465 -0.146528  0.308760 -0.507710  \n",
       "1  0.177566 -0.279586 -0.090004  0.288699 -0.116357  0.282336 -0.485791  \n",
       "2  0.193854 -0.275070 -0.083573  0.291871 -0.119588  0.284721 -0.480852  \n",
       "3  0.234967 -0.267003 -0.111241  0.301085 -0.106685  0.278395 -0.487310  \n",
       "4  0.213321 -0.256279 -0.078744  0.296476 -0.133884  0.246727 -0.495191  \n",
       "\n",
       "[5 rows x 300 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testDataVecs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP1_wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(300, 300), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=300, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "       verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Establish and fit the model, with various parameters\n",
    "mlp1_wv = MLPClassifier(activation='relu', alpha=0.0001, hidden_layer_sizes=(300, 300), max_iter=300)\n",
    "mlp1_wv.fit(trainDataVecs, train_sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the classifer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6264 0.6164 0.6036 0.6072 0.606 ]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7507</td>\n",
       "      <td>4993</td>\n",
       "      <td>12500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4584</td>\n",
       "      <td>7916</td>\n",
       "      <td>12500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>12091</td>\n",
       "      <td>12909</td>\n",
       "      <td>25000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted      0      1    All\n",
       "True                          \n",
       "0           7507   4993  12500\n",
       "1           4584   7916  12500\n",
       "All        12091  12909  25000"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(cross_val_score(mlp1_wv, testDataVecs, test_sent, cv=5))\n",
    "y_mlp1_pred = mlp1_wv.predict(testDataVecs)\n",
    "pd.crosstab(test_sent, y_mlp1_pred, rownames=['True'], colnames=['Predicted'], margins=True)\n",
    "#classification_report(train_sent, y_mlp1_pred, target_names=target_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP2_wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.05, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(300, 300), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=300, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "       verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Establish and fit the model, with various parameters\n",
    "mlp2_wv = MLPClassifier(activation='relu', alpha=0.05, hidden_layer_sizes=(300, 300), max_iter=300)\n",
    "mlp2_wv.fit(trainDataVecs, train_sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the classifer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6264 0.623  0.58   0.6098 0.607 ]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7776</td>\n",
       "      <td>4724</td>\n",
       "      <td>12500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4814</td>\n",
       "      <td>7686</td>\n",
       "      <td>12500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>12590</td>\n",
       "      <td>12410</td>\n",
       "      <td>25000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted      0      1    All\n",
       "True                          \n",
       "0           7776   4724  12500\n",
       "1           4814   7686  12500\n",
       "All        12590  12410  25000"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(cross_val_score(mlp2_wv, testDataVecs, test_sent, cv=5))\n",
    "y_mlp2_pred = mlp2_wv.predict(testDataVecs)\n",
    "pd.crosstab(test_sent, y_mlp2_pred, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP3_wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(1000, 300), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=300, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "       verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Establish and fit the model, with various parameters\n",
    "mlp3_wv = MLPClassifier(activation='relu', alpha=0.0001, hidden_layer_sizes=(1000, 300), max_iter=300)\n",
    "mlp3_wv.fit(trainDataVecs, train_sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the classifer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5178 0.508  0.5064 0.5194 0.5106]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10088</td>\n",
       "      <td>2412</td>\n",
       "      <td>12500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9817</td>\n",
       "      <td>2683</td>\n",
       "      <td>12500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>19905</td>\n",
       "      <td>5095</td>\n",
       "      <td>25000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted      0     1    All\n",
       "True                         \n",
       "0          10088  2412  12500\n",
       "1           9817  2683  12500\n",
       "All        19905  5095  25000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(cross_val_score(mlp3_wv, testDataVecs, test_sent, cv=5))\n",
    "y_mlp3_pred = mlp3_wv.predict(testDataVecs)\n",
    "pd.crosstab(test_sent, y_mlp3_pred, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP4_wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(1000, 300), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=300, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "       verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Establish and fit the model, with various parameters\n",
    "mlp4_wv = MLPClassifier(activation='relu', alpha=0.0001, hidden_layer_sizes=(1000, 300), max_iter=300)\n",
    "mlp4_wv.fit(trainDataVecs, train_sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the classifer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7890</td>\n",
       "      <td>4610</td>\n",
       "      <td>12500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4942</td>\n",
       "      <td>7558</td>\n",
       "      <td>12500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>12832</td>\n",
       "      <td>12168</td>\n",
       "      <td>25000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted      0      1    All\n",
       "True                          \n",
       "0           7890   4610  12500\n",
       "1           4942   7558  12500\n",
       "All        12832  12168  25000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print(cross_val_score(mlp4_wv, testDataVecs, test_sent, cv=5))\n",
    "y_mlp4_pred = mlp4_wv.predict(testDataVecs)\n",
    "pd.crosstab(test_sent, y_mlp4_pred, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP5_wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(1000, 3), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "       verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Establish and fit the model, with various parameters\n",
    "mlp5_wv = MLPClassifier(activation='relu', alpha=0.0001, hidden_layer_sizes=(1000, 3), max_iter=200)\n",
    "mlp5_wv.fit(trainDataVecs, train_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5521</td>\n",
       "      <td>6979</td>\n",
       "      <td>12500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3057</td>\n",
       "      <td>9443</td>\n",
       "      <td>12500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>8578</td>\n",
       "      <td>16422</td>\n",
       "      <td>25000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted     0      1    All\n",
       "True                         \n",
       "0          5521   6979  12500\n",
       "1          3057   9443  12500\n",
       "All        8578  16422  25000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print(cross_val_score(mlp5_wv, testDataVecs, test_sent, cv=5))\n",
    "y_mlp5_pred = mlp5_wv.predict(testDataVecs)\n",
    "pd.crosstab(test_sent, y_mlp5_pred, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP6_wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(1000, 500), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=300, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "       verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Establish and fit the model, with various parameters\n",
    "mlp6_wv = MLPClassifier(hidden_layer_sizes=(1000, 500), max_iter=300)\n",
    "mlp6_wv.fit(trainDataVecs, train_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6216 0.6064 0.6136 0.6074 0.546 ]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5521</td>\n",
       "      <td>6979</td>\n",
       "      <td>12500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3057</td>\n",
       "      <td>9443</td>\n",
       "      <td>12500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>8578</td>\n",
       "      <td>16422</td>\n",
       "      <td>25000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted     0      1    All\n",
       "True                         \n",
       "0          5521   6979  12500\n",
       "1          3057   9443  12500\n",
       "All        8578  16422  25000"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(cross_val_score(mlp6_wv, testDataVecs, test_sent, cv=5))\n",
    "y_mlp6_pred = mlp5_wv.predict(testDataVecs)\n",
    "pd.crosstab(test_sent, y_mlp6_pred, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP7_wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(1000, 3), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "       verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Establish and fit the model, with various parameters\n",
    "mlp7_wv = MLPClassifier(hidden_layer_sizes=(1000, 3))\n",
    "mlp7_wv.fit(trainDataVecs, train_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5    0.5    0.5916 0.5    0.5588]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10246</td>\n",
       "      <td>2254</td>\n",
       "      <td>12500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7737</td>\n",
       "      <td>4763</td>\n",
       "      <td>12500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>17983</td>\n",
       "      <td>7017</td>\n",
       "      <td>25000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted      0     1    All\n",
       "True                         \n",
       "0          10246  2254  12500\n",
       "1           7737  4763  12500\n",
       "All        17983  7017  25000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(cross_val_score(mlp7_wv, testDataVecs, test_sent, cv=5))\n",
    "y_mlp7_pred = mlp7_wv.predict(testDataVecs)\n",
    "pd.crosstab(test_sent, y_mlp7_pred, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP8_wv and MLP9_wv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP1_wv_logistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='logistic', alpha=0.0001, batch_size='auto',\n",
       "       beta_1=0.9, beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(1000, 500), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=300, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "       verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Establish and fit the model, with various parameters\n",
    "mlp1logistic_wv = MLPClassifier(activation='logistic', alpha=0.0001, hidden_layer_sizes=(1000, 500), max_iter=300)\n",
    "mlp1logistic_wv.fit(trainDataVecs, train_sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the classifer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7890</td>\n",
       "      <td>4610</td>\n",
       "      <td>12500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4942</td>\n",
       "      <td>7558</td>\n",
       "      <td>12500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>12832</td>\n",
       "      <td>12168</td>\n",
       "      <td>25000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted      0      1    All\n",
       "True                          \n",
       "0           7890   4610  12500\n",
       "1           4942   7558  12500\n",
       "All        12832  12168  25000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print(cross_val_score(mlp4_wv, testDataVecs, test_sent, cv=5))\n",
    "y_mlp1logistic_pred = mlp4_wv.predict(testDataVecs)\n",
    "pd.crosstab(test_sent, y_mlp1logistic_pred, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_wv = LogisticRegression()\n",
    "classifier_wv.fit(trainDataVecs, train_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.86728\n"
     ]
    }
   ],
   "source": [
    "cross_val_score(classifier_wv, test_arrays, test_labels, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10838</td>\n",
       "      <td>1662</td>\n",
       "      <td>12500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1656</td>\n",
       "      <td>10844</td>\n",
       "      <td>12500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>12494</td>\n",
       "      <td>12506</td>\n",
       "      <td>25000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted      0      1    All\n",
       "True                          \n",
       "0          10838   1662  12500\n",
       "1           1656  10844  12500\n",
       "All        12494  12506  25000"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_logis_pred = classifier.predict(testDataVecs)\n",
    "3confusion_mat = confusion_matrix(test_sent, y_logis_pred)\n",
    "pd.crosstab(test_sent, y_logis_pred, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_mat = confusion_matrix(test_sent, y_logis_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Doc2Vec\n",
    "* How does Doc2Vec work?\n",
    "Doc2Vec does essentially the same thing we did above, vectorizes the word and \"aggregates\" the words to represent the document.\n",
    "* The differece is the way it aggregates the vectors, and how does Doc2Vec does that?\n",
    "Doc2Vec treats all the documents as \"labeled\" word and does \"mathameaticl trick\" to represent that word as a vector. The label here will be the name of the file each review contains in.\n",
    "* format\n",
    "Doc2Vec like word to Word2Vec, expects sentences and each sentnce as a list of words, and each sentence is labled. To acomplish this we will be using LabeledSentence class (see code below)\n",
    "* What is this mathamatical trick?\n",
    "labeled documents goes into a neural network and creates word embedding just like the Word2Vec with word window for context and document embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LabeledLineSentence(object):\n",
    "    def __init__(self, doc_list, labels_list):\n",
    "       self.labels_list = labels_list\n",
    "       self.doc_list = doc_list\n",
    "    def __iter__(self):\n",
    "        for idx, doc in enumerate(self.doc_list):\n",
    "            yield TaggedDocument(words=doc,tags=[self.labels_list[idx]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'clean_review' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-e8157edf8f2d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtagged_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLabeledLineSentence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclean_review\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'file'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'clean_review' is not defined"
     ]
    }
   ],
   "source": [
    "tagged_data = LabeledLineSentence(clean_review, data_df['file'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-family:Helvetica Neue;font-size:20px\">another method is to use doc2vec module\n",
    "<br> build the model</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Doc2Vec(\n",
    "    workers=4,     # Number of threads to run in parallel (if your computer does parallel processing).\n",
    "    min_count=1,  # Minimum word count threshold.\n",
    "    window=6,      # Number of words around target word to consider.\n",
    "    #sg=0,          # Use CBOW because our corpus is small.\n",
    "    sample=1e-3 ,  # Penalize frequent words.\n",
    "    vector_size=300,      # Word vector length.\n",
    "    hs=1,           # Use hierarchical softmax.\n",
    "    alpha = 0.0002, # decrease the learing rate\n",
    "    min_alpha = 0.0002 # fix the learing rate, no dacay\n",
    "    \n",
    ")\n",
    "\n",
    "model2.build_vocab(tagged_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-family:Helvetica Neue;font-size:20px\">Here we are training the model by controling the learning rate and iterating over the documents multiple times for better result[1]\n",
    "<br>\n",
    "<br>[1] https://rare-technologies.com/doc2vec-tutorial/ </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0\n",
      "iteration 1\n",
      "iteration 2\n",
      "iteration 3\n",
      "iteration 4\n",
      "iteration 5\n",
      "iteration 6\n",
      "iteration 7\n",
      "iteration 8\n",
      "iteration 9\n"
     ]
    }
   ],
   "source": [
    "#iterating multiple times trians gives better result as claimed by rare-technologies\n",
    "for epoch in range(10):\n",
    "    print('iteration {0}'.format(epoch))\n",
    "    model2.train(tagged_data, total_examples=model2.corpus_count, epochs=model2.epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-family:Helvetica Neue;font-size:20px\"> not a great result, can be impoved with feature engenering, delet less of text, add more data, and add parts of speach.\n",
    "<br>\n",
    "<br>\n",
    "traing and test data split with vectorization of the documents<p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task list\n",
    "\n",
    "<ol style=\"font-family:Helvetica Neue;font-size:20px\">\n",
    "    <li>Importing the data</li>\n",
    "    <li>Cleaning the review text:\n",
    "        <ol>\n",
    "            <li>Regular expression operations (re): removed spicfied strings</li>\n",
    "            <li>beautiful soup: HTML tags</li>\n",
    "            <li>NLTK: parts of speach</li>\n",
    "            <li>python functions</li>\n",
    "        </ol>\n",
    "    </li>\n",
    "    <li>Vetorizing using Word2Vec:\n",
    "        <ol>\n",
    "            <li>Test vectors</li>\n",
    "            <li>Graph word vectors:\n",
    "                <ol>\n",
    "                    <li>Reduce vectors to two dimension using tsne</li>\n",
    "                </ol>\n",
    "            </li>\n",
    "            <li>Average the vectors of words in the documents to create document vectors representation\n",
    "                <ol>\n",
    "                    <li>Creat a classifier Multi level preceptron (MLP) model using the documents vectors\n",
    "                        <ol>\n",
    "                            <li>model was run for few different hyperparameters with activation='relu' due to lack of resouces</li>\n",
    "                            <li>gridsearch was run for hyperparameter with activation='logistic' on differen computer.\n",
    "                        </ol>\n",
    "                    </li>\n",
    "                    <li>Try out ELM</li>\n",
    "                </ol>\n",
    "            </li>\n",
    "     <li>Vetorization using Doc2Vec\n",
    "         <ol>\n",
    "             <li>Test vectors</li>\n",
    "             <li>Unable to graph</li>\n",
    "             <li>gridsearch</li>\n",
    "         </ol>\n",
    "         </ol>\n",
    "    </li>\n",
    "</ol>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
