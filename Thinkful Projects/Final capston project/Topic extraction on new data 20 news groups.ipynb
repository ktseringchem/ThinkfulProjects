{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import scipy\n",
    "import spacy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from os import listdir\n",
    "import matplotlib.pyplot as plt\n",
    "from os.path import isfile, join\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Comparing LSA, LDA, and NNMF\n",
    "Take the well-known 20 newsgroups dataset and use each of the methods on it. Your goal is to determine which method, if any, best reproduces the topics represented by the newsgroups. Write up a report where you evaluate each method in light of the 'ground truth'- the known source of each newsgroup post. Which works best, and why do you think this is the case?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saves list of files names to loop though\n",
    "atheism_file_names = ['20news-18828\\\\alt.atheism\\\\{}'.format(f) for f in listdir('20news-18828\\\\alt.atheism') if isfile(join('20news-18828\\\\alt.atheism', f))]\n",
    "compGraphic_file_names = ['20news-18828\\\\comp.graphics\\\\{}'.format(f) for f in listdir('20news-18828\\\\comp.graphics') if isfile(join('20news-18828\\\\comp.graphics', f))]\n",
    "lite_file_names = compGraphic_file_names[0:10] + atheism_file_names[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en')\n",
    "pattern = \"[-|*&#$%\\?/<>()\\d\\\\t]\"\n",
    "atheism_df = []\n",
    "i = 0\n",
    "for file in lite_file_names:\n",
    "    file1_open = open(file)\n",
    "    file1_content = file1_open.read()\n",
    "    #removing the double-dash from all words\n",
    "    file1_content=file1_content.replace('\\\\', '')\n",
    "    file1_content=[re.sub(r'\\n','',word) for word in file1_content]\n",
    "    file1_content=[re.sub(pattern,'',word) for word in file1_content]\n",
    "    if i < 9:\n",
    "        atheism_df.append([''.join(file1_content), 'Comp Graphic'])\n",
    "    else:\n",
    "        atheism_df.append([''.join(file1_content), 'atheism'])\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the tf-idf matrix.\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "emma_paras_tfidf=vectorizer.fit_transform(atheism_df[0])\n",
    "\n",
    "terms = vectorizer.get_feature_names()\n",
    "\n",
    "# Number of topics.\n",
    "ntopics=2\n",
    "\n",
    "# Linking words to topics\n",
    "def word_topic(tfidf,solution, wordlist):\n",
    "    \n",
    "    # Loading scores for each word on each topic/component.\n",
    "    words_by_topic=tfidf.T * solution\n",
    "\n",
    "    # Linking the loadings to the words in an easy-to-read way.\n",
    "    components=pd.DataFrame(words_by_topic,index=wordlist)\n",
    "    \n",
    "    return components\n",
    "\n",
    "# Extracts the top N words and their loadings for each topic.\n",
    "def top_words(components, n_top_words):\n",
    "    n_topics = range(components.shape[1])\n",
    "    index= np.repeat(n_topics, n_top_words, axis=0)\n",
    "    topwords=pd.Series(index=index)\n",
    "    for column in range(components.shape[1]):\n",
    "        # Sort the column so that highest loadings are at the top.\n",
    "        sortedwords=components.iloc[:,column].sort_values(ascending=False)\n",
    "        # Choose the N highest loadings.\n",
    "        chosen=sortedwords[:n_top_words]\n",
    "        # Combine loading and index into a string.\n",
    "        chosenlist=chosen.index +\" \"+round(chosen,2).map(str) \n",
    "        topwords.loc[column]=chosenlist\n",
    "    return(topwords)\n",
    "\n",
    "# Number of words to look at for each topic.\n",
    "n_top_words = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# LSA\n",
    "\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "svd= TruncatedSVD(ntopics)\n",
    "lsa = make_pipeline(svd, Normalizer(copy=False))\n",
    "emma_paras_lsa = lsa.fit_transform(emma_paras_tfidf)\n",
    "\n",
    "components_lsa = word_topic(emma_paras_tfidf, emma_paras_lsa, terms)\n",
    "\n",
    "topwords=pd.DataFrame()\n",
    "topwords['LSA']=top_words(components_lsa, n_top_words)                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ktser\\Anaconda3\\lib\\site-packages\\sklearn\\decomposition\\online_lda.py:294: DeprecationWarning: n_topics has been renamed to n_components in version 0.19 and will be removed in 0.21\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\ktser\\Anaconda3\\lib\\site-packages\\sklearn\\decomposition\\online_lda.py:536: DeprecationWarning: The default value for 'learning_method' will be changed from 'online' to 'batch' in the release 0.20. This warning was introduced in 0.18.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# LDA\n",
    "from sklearn.decomposition import LatentDirichletAllocation as LDA\n",
    "\n",
    "lda = LDA(n_topics=ntopics, \n",
    "          doc_topic_prior=None, # Prior = 1/n_documents\n",
    "          topic_word_prior=1/ntopics,\n",
    "          learning_decay=0.7, # Convergence rate.\n",
    "          learning_offset=10.0, # Causes earlier iterations to have less influence on the learning\n",
    "          max_iter=10, # when to stop even if the model is not converging (to prevent running forever)\n",
    "          evaluate_every=-1, # Do not evaluate perplexity, as it slows training time.\n",
    "          mean_change_tol=0.001, # Stop updating the document topic distribution in the E-step when mean change is < tol\n",
    "          max_doc_update_iter=100, # When to stop updating the document topic distribution in the E-step even if tol is not reached\n",
    "          n_jobs=-1, # Use all available CPUs to speed up processing time.\n",
    "          verbose=0, # amount of output to give while iterating\n",
    "          random_state=0\n",
    "         )\n",
    "\n",
    "emma_paras_lda = lda.fit_transform(emma_paras_tfidf) \n",
    "\n",
    "components_lda = word_topic(emma_paras_tfidf, emma_paras_lda, terms)\n",
    "\n",
    "topwords['LDA']=top_words(components_lda, n_top_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# NNMF\n",
    "\n",
    "from sklearn.decomposition import NMF\n",
    "\n",
    "nmf = NMF(alpha=0.0, \n",
    "          init='nndsvdar', # how starting value are calculated\n",
    "          l1_ratio=0.0, # Sets whether regularization is L2 (0), L1 (1), or a combination (values between 0 and 1)\n",
    "          max_iter=200, # when to stop even if the model is not converging (to prevent running forever)\n",
    "          n_components=ntopics, \n",
    "          random_state=0, \n",
    "          solver='cd', # Use Coordinate Descent to solve\n",
    "          tol=0.0001, # model will stop if tfidf-WH <= tol\n",
    "          verbose=0 # amount of output to give while iterating\n",
    "         )\n",
    "emma_paras_nmf = nmf.fit_transform(emma_paras_tfidf) \n",
    "\n",
    "components_nmf = word_topic(emma_paras_tfidf, emma_paras_nmf, terms)\n",
    "\n",
    "topwords['NNMF']=top_words(components_nmf, n_top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0:\n",
      "                   LSA                 LDA                NNMF\n",
      "0            comp 0.71           navy 0.36           navy 0.39\n",
      "0         graphic 0.71         lipman 0.24         lipman 0.26\n",
      "0  worksinprogress 0.0  presentations 0.24  presentations 0.26\n",
      "0             legs 0.0   visualization 0.2  visualization 0.22\n",
      "0               dt 0.0         virtual 0.2        virtual 0.22\n",
      "0            email 0.0      scientific 0.2        reality 0.22\n",
      "0      engineering 0.0         reality 0.2     scientific 0.22\n",
      "0         exchange 0.0           comp 0.17        seminar 0.17\n",
      "0         factsnet 0.0        graphic 0.17   presentation 0.17\n",
      "0              fax 0.0             dt 0.16             dt 0.17\n",
      "0   fornavyrelated 0.0        seminar 0.16         robert 0.17\n",
      "0            group 0.0         robert 0.16         center 0.13\n",
      "0          include 0.0   presentation 0.16          oasys 0.13\n",
      "0      information 0.0       bethesda 0.12       bethesda 0.13\n",
      "0         internet 0.0         center 0.12            fax 0.09\n",
      "Topic 1:\n",
      "                  LSA                 LDA                 NNMF\n",
      "1           navy 0.39           comp 0.54            comp 0.71\n",
      "1         lipman 0.26        graphic 0.54         graphic 0.71\n",
      "1  presentations 0.26           navy 0.04  worksinprogress 0.0\n",
      "1  visualization 0.22         lipman 0.02             legs 0.0\n",
      "1        virtual 0.22  presentations 0.02               dt 0.0\n",
      "1        reality 0.22  visualization 0.02            email 0.0\n",
      "1     scientific 0.22        virtual 0.02      engineering 0.0\n",
      "1        seminar 0.17     scientific 0.02         exchange 0.0\n",
      "1   presentation 0.17        reality 0.02         factsnet 0.0\n",
      "1             dt 0.17             dt 0.02              fax 0.0\n",
      "1         robert 0.17        seminar 0.02   fornavyrelated 0.0\n",
      "1         center 0.13         robert 0.02            group 0.0\n",
      "1          oasys 0.13   presentation 0.02          include 0.0\n",
      "1       bethesda 0.13       bethesda 0.01      information 0.0\n",
      "1            fax 0.09         center 0.01         internet 0.0\n"
     ]
    }
   ],
   "source": [
    "for topic in range(ntopics):\n",
    "    print('Topic {}:'.format(topic))\n",
    "    print(topwords.loc[topic])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d86de9dc7acc4662a9b970c9424b33ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ipywidgets import IntSlider\n",
    "slider = IntSlider(value=50)\n",
    "slider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "slider.value = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return x**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43384b78673f40e98327d6207e459061",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.f>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interact(f, x=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
