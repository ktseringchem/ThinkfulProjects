{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentimental Review of the movie reviews\n",
    "\n",
    "### by Karma Tsering\n",
    "My goal is to predict sentiment of each movie reviews."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Motivation of this project\n",
    "There are too many movies and too many people with opnion on them. Its doubtful that any one would want to read these reviews, certly not companies that need to \n",
    "\n",
    "### Data Source\n",
    "This dataset contains movie reviews along with their associated binary sentiment polarity labels. It is intended to serve as a benchmark for sentiment classification. \n",
    "\n",
    "The core dataset contains 50,000 reviews split evenly into 25k train and 25k test sets. The overall distribution of labels is balanced (25k pos and 25k neg). \n",
    "\n",
    "In the entire collection, no more than 30 reviews are allowed for any given movie because reviews for the same movie tend to have correlated ratings. In the labeled train/test sets, a negative review has a score <= 4 out of 10, and a positive review has a score >= 7 out of 10. Thus reviews with more neutral ratings are not included in the train/test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from os import listdir\n",
    "%matplotlib inline\n",
    "\n",
    "import spacy\n",
    "nlp = spacy.load('en')\n",
    "\n",
    "import scipy\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "import re\n",
    "from os.path import isfile, join\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#saves list of files names to loop though\n",
    "neg_train_file_names = [f for f in listdir('aclImdb\\\\train\\\\neg') if isfile(join('aclImdb\\\\train\\\\neg', f))]\n",
    "pos_train_file_names = [f for f in listdir('aclImdb\\\\train\\\\pos') if isfile(join('aclImdb\\\\train\\\\pos', f))]\n",
    "neg_test_file_names = [f for f in listdir('aclImdb\\\\test\\\\neg') if isfile(join('aclImdb\\\\test\\\\neg', f))]\n",
    "pos_test_file_names = [f for f in listdir('aclImdb\\\\test\\\\pos') if isfile(join('aclImdb\\\\test\\\\pos', f))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#The reviews are saved in each individual files, so I looped through each file and saved the content of the files as \n",
    "#and assigned a sentement based on which folder the file was in (neg = 0/ pos = 1).\n",
    "review_df1 = []\n",
    "review_df2 = []\n",
    "review_df3 = []\n",
    "review_df4 = []\n",
    "\n",
    "for file in neg_train_file_names:\n",
    "    file1_open = open(\"aclImdb\\\\train\\\\neg\\\\{}\".format(file), encoding=\"utf8\")\n",
    "    file1_content = file1_open.read()\n",
    "    review_df1.append([file1_content, 0])\n",
    "    \n",
    "for file in pos_train_file_names:\n",
    "    file1_open = open(\"aclImdb\\\\train\\\\pos\\\\{}\".format(file), encoding=\"utf8\")\n",
    "    file1_content = file1_open.read()\n",
    "    review_df2.append([file1_content, 1])\n",
    "\n",
    "for file in neg_test_file_names:\n",
    "    file1_open = open(\"aclImdb\\\\test\\\\neg\\\\{}\".format(file), encoding=\"utf8\")\n",
    "    file1_content = file1_open.read()\n",
    "    review_df3.append([file1_content, 0])\n",
    "\n",
    "for file in pos_test_file_names:\n",
    "    file1_open = open(\"aclImdb\\\\test\\\\pos\\\\{}\".format(file), encoding=\"utf8\")\n",
    "    file1_content = file1_open.read()\n",
    "    review_df4.append([file1_content, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Put them in DataFrame format\n",
    "review_df1 = pd.DataFrame(review_df1)\n",
    "review_df2 = pd.DataFrame(review_df2)\n",
    "review_df3 = pd.DataFrame(review_df3)\n",
    "review_df4 = pd.DataFrame(review_df4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I saw this film as a sneak preview before the ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DON'T TORTURE A DUCKLING (Lucio Fulci - Italy ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>too bad this movie isn't. While \"Nemesis Game\"...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Amazing, one of my favorite movies way down at...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>At the surface COOLEY HIGH is a snappy ensembl...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>This movie was produced by the biggest produce...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>I found this film by mistake many years ago &amp; ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>This movie makes Peter an elf in Robin Hood co...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>I feel the movie did not portray Smith histori...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>I just re-watched 08th MS Gundam for the 2nd t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  Rating\n",
       "0  I saw this film as a sneak preview before the ...       0\n",
       "1  DON'T TORTURE A DUCKLING (Lucio Fulci - Italy ...       1\n",
       "2  too bad this movie isn't. While \"Nemesis Game\"...       0\n",
       "3  Amazing, one of my favorite movies way down at...       1\n",
       "4  At the surface COOLEY HIGH is a snappy ensembl...       1\n",
       "5  This movie was produced by the biggest produce...       0\n",
       "6  I found this film by mistake many years ago & ...       1\n",
       "7  This movie makes Peter an elf in Robin Hood co...       0\n",
       "8  I feel the movie did not portray Smith histori...       0\n",
       "9  I just re-watched 08th MS Gundam for the 2nd t...       1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#put all the above dataframe in one dataframe\n",
    "review_df = pd.concat([review_df1, review_df2, review_df3, review_df4]).sample(frac=1).reset_index(drop=True)\n",
    "review_df.columns = ['Review', 'Rating']\n",
    "print(review_df.shape)\n",
    "review_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Frame created above\n",
    "\n",
    "# text file for making BOW\n",
    "Put all the reviews in one string in perperation for extrating key words to be used as feature later on for creating vector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pick 2000 words and make BOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#I cleanded the text as much as possible so to reduce load for nlp processing and to increase the number of vocas for feature\n",
    "from nltk.corpus import stopwords\n",
    "stopWords = stopwords.words('english')\n",
    "allwords = \" \"\n",
    "Review = []\n",
    "pattern = \"[-*:!&$%',.\\\\?\\\"/<>()\\d]\"\n",
    "pattern2 = r\"\\bbr\\b\"\n",
    "pattern3 = r'\\bA\\b'\n",
    "pattern4 = r'--'\n",
    "#pattern5 = '.+;$'\n",
    "\n",
    "for review in review_df['Review']:\n",
    "    #cleaning up each review text by removing above patters\n",
    "    mov_review = re.sub(pattern, \"\", review)\n",
    "    mov_review = re.sub(pattern2, \"\", mov_review)\n",
    "    mov_review = re.sub(pattern3, \"\", mov_review)\n",
    "    mov_review = re.sub(pattern4, \"\", mov_review)\n",
    "    #mov_review = re.sub(pattern5, \"\", mov_review)\n",
    "    mov_review = mov_review.split()\n",
    "    mov_review = [x for x in mov_review\n",
    "                if not x == ' '\n",
    "                and not x == 's'\n",
    "                and not x == 'I'\n",
    "                and not x == 'movie'\n",
    "                and not x == '-PRON-'\n",
    "                and not x == 'film'\n",
    "                and not x == '\\x96'\n",
    "                and not x == '!'\n",
    "                and x not in stopWords]\n",
    "\n",
    "    #Collect all review as string to make BOW later\n",
    "    #allwords = allwords + mov_review\n",
    "    Review.append(mov_review)\n",
    "    allwords = allwords + ' ' +' '.join(mov_review)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Above the string text has been worked to reduce the nlp processing work below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#nlp processing\n",
    "#there seems to a limit of million char for nlp processing so I did it twice to get more feature\n",
    "allwords_doc1 = nlp(allwords[0:999999])\n",
    "allwords_doc2 = nlp(allwords[999999:1999998])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Removing stop words help in creating meaningful features\n",
    "from nltk.corpus import stopwords\n",
    "stopWords = set(stopwords.words('english'))\n",
    "\n",
    "#save only the words we care about\n",
    "def bag_of_words(text):\n",
    "    allwords = [token.lemma_\n",
    "                    for token in text\n",
    "                    if not token.is_punct\n",
    "                    and not token.is_stop]\n",
    "    allwords = [x for x in allwords\n",
    "                if not x == ' '\n",
    "                and not x == 's'\n",
    "                and not x == 'movie'\n",
    "                and not x == '-PRON-'\n",
    "                and not x == 'film'\n",
    "                and x not in stopWords]\n",
    "   \n",
    "    return allwords\n",
    "\n",
    "#run both processed nlp text\n",
    "word_count1 = [item[0] for item  in Counter(bag_of_words(allwords_doc1)).most_common(4000)]\n",
    "word_count2 = [item[0] for item  in Counter(bag_of_words(allwords_doc2)).most_common(4000)]\n",
    "\n",
    "#combaining both bag of words and removing duplicates\n",
    "word_count = set(word_count1 + word_count2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a df with word in the bag of words, make feature of them, and count how many there are in each review. Those count will be the data point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bow_features(review_df, word_count):\n",
    "    \n",
    "    # Scaffold the data frame and initialize counts to zero.\n",
    "    df = pd.DataFrame(columns=word_count)\n",
    "    df['text_sentence'] = review_df['Review'][0:20000]\n",
    "    df['text_source'] = review_df['Rating'][0:20000]\n",
    "    df.loc[:, word_count] = 0\n",
    "    \n",
    "    # Process each row, counting the occurrence of words in each sentence.\n",
    "    for i, sentence in enumerate(df['text_sentence']):\n",
    "        \n",
    "        sentence = nlp(sentence)\n",
    "        # Convert the sentence to lemmas, then filter out punctuation,\n",
    "        # stop words, and uncommon words.\n",
    "        words = [token.lemma_\n",
    "                 for token in sentence\n",
    "                 if (\n",
    "                     not token.is_punct\n",
    "                     and not token.is_stop\n",
    "                     and token.lemma_ in word_count\n",
    "                 )]\n",
    "        \n",
    "        # Populate the row with word counts.\n",
    "        for word in words:\n",
    "            df.loc[i, word] += 1\n",
    "        \n",
    "        # This counter is just to make sure the kernel didn't hang.\n",
    "        if i % 500 == 0:\n",
    "            print(\"Processing row {}\".format(i))\n",
    "            \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#this takes too long so I only included 20,000 review. \n",
    "#word_counts = bow_features(review_df, word_count)\n",
    "#word_counts\n",
    "#I ran the above code and saved the file as 'Review_with_feature.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>relevant</th>\n",
       "      <th>compare</th>\n",
       "      <th>uplift</th>\n",
       "      <th>campus</th>\n",
       "      <th>shrink</th>\n",
       "      <th>metal</th>\n",
       "      <th>farscape</th>\n",
       "      <th>earlier</th>\n",
       "      <th>ultimate</th>\n",
       "      <th>...</th>\n",
       "      <th>loud</th>\n",
       "      <th>flavor</th>\n",
       "      <th>arc</th>\n",
       "      <th>assassination</th>\n",
       "      <th>commentator</th>\n",
       "      <th>contract</th>\n",
       "      <th>charming</th>\n",
       "      <th>underground</th>\n",
       "      <th>text_sentence</th>\n",
       "      <th>text_source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>WWII veterans return home and find it hard to ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>This is an incredible movie that begins slowly...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>It worked! Director Christian Duguay created a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Spin-offs, for somebody who don't know, are no...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...about this film was the title song. After 3...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 5052 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  relevant  compare  uplift  campus  shrink  metal  farscape  \\\n",
       "0           0         0        0       0       0       0      0         0   \n",
       "1           1         0        0       0       0       0      0         0   \n",
       "2           2         0        0       0       0       0      0         0   \n",
       "3           3         0        0       0       0       0      0         0   \n",
       "4           4         0        0       0       0       0      0         0   \n",
       "\n",
       "   earlier  ultimate     ...       loud  flavor  arc  assassination  \\\n",
       "0        0         0     ...          0       0    0              0   \n",
       "1        0         0     ...          0       0    0              0   \n",
       "2        0         0     ...          0       0    0              0   \n",
       "3        0         0     ...          0       0    0              0   \n",
       "4        0         0     ...          0       0    0              0   \n",
       "\n",
       "   commentator  contract  charming  underground  \\\n",
       "0            0         0         0            0   \n",
       "1            0         0         0            0   \n",
       "2            0         0         0            0   \n",
       "3            0         0         0            0   \n",
       "4            0         0         0            0   \n",
       "\n",
       "                                       text_sentence  text_source  \n",
       "0  WWII veterans return home and find it hard to ...            1  \n",
       "1  This is an incredible movie that begins slowly...            1  \n",
       "2  It worked! Director Christian Duguay created a...            1  \n",
       "3  Spin-offs, for somebody who don't know, are no...            1  \n",
       "4  ...about this film was the title song. After 3...            0  \n",
       "\n",
       "[5 rows x 5052 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#loading df from saved file\n",
    "review_feature_df = pd.read_csv('Review_with_feature.csv', encoding=\"ISO-8859-1\")\n",
    "review_feature_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#trying gridsearch on subsection of the dataset becasue it is process intensive but it didn't help so result won't be included\n",
    "review_feature_df2 = review_feature_df[0:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#split the dataset into train and test sets, with test size of 40% becasue it gives me better result\n",
    "X = review_feature_df.drop(['text_sentence', 'text_source'], 1)\n",
    "y = review_feature_df['text_source']\n",
    "\n",
    "X_pca = PCA(n_components=5).fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_pca, \n",
    "                                                    y,\n",
    "                                                    test_size=0.4,\n",
    "                                                    random_state=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BoW with Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12000, 5049) (12000,)\n",
      "Training set score: 0.98375\n",
      "\n",
      "Test set score: 0.84275\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_source</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5887</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>83</td>\n",
       "      <td>5918</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0           0     1\n",
       "text_source            \n",
       "0            5887   112\n",
       "1              83  5918"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#First trying some classicication models starting with logistic regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression()\n",
    "train = lr.fit(X_train, y_train)\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print('Training set score:', lr.score(X_train, y_train))\n",
    "print('\\nTest set score:', lr.score(X_test, y_test))\n",
    "\n",
    "y_pred = lr.predict(X_train)\n",
    "pd.crosstab(y_train, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_source</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3383</td>\n",
       "      <td>618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>640</td>\n",
       "      <td>3359</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0           0     1\n",
       "text_source            \n",
       "0            3383   618\n",
       "1             640  3359"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = lr.predict(X_test)\n",
    "pd.crosstab(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.9933333333333333\n",
      "\n",
      "Test set score: 0.75725\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_source</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5991</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>72</td>\n",
       "      <td>5929</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0           0     1\n",
       "text_source            \n",
       "0            5991     8\n",
       "1              72  5929"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import ensemble\n",
    "\n",
    "rfc = ensemble.RandomForestClassifier()\n",
    "\n",
    "train = rfc.fit(X_train, y_train)\n",
    "\n",
    "print('Training set score:', rfc.score(X_train, y_train))\n",
    "print('\\nTest set score:', rfc.score(X_test, y_test))\n",
    "\n",
    "y_pred = rfc.predict(X_train)\n",
    "pd.crosstab(y_train, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_source</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3300</td>\n",
       "      <td>701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1241</td>\n",
       "      <td>2758</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0           0     1\n",
       "text_source            \n",
       "0            3300   701\n",
       "1            1241  2758"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = rfc.predict(X_test)\n",
    "pd.crosstab(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GradientBoosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.8171666666666667\n",
      "\n",
      "Test set score: 0.78925\n"
     ]
    }
   ],
   "source": [
    "clf = ensemble.GradientBoostingClassifier()\n",
    "train = clf.fit(X_train, y_train)\n",
    "\n",
    "print('Training set score:', clf.score(X_train, y_train))\n",
    "print('\\nTest set score:', clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.66725\n",
      "col_0           0     1\n",
      "text_source            \n",
      "0            3861  2138\n",
      "1            1855  4146\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svm = SVC(kernel = 'linear')\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "print('Training set score:', svm.score(X_train, y_train))\n",
    "y_pred1 = svm.predict(X_train)\n",
    "print(pd.crosstab(y_train, y_pred1))\n",
    "\n",
    "#print('\\nTest set score:', svm.score(X_test, y_test))\n",
    "#y_pred2 = svm.predict(X_test)\n",
    "#pd.crosstab(y_test, y_pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.68      0.64      0.66      5999\n",
      "          1       0.66      0.69      0.67      6001\n",
      "\n",
      "avg / total       0.67      0.67      0.67     12000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics iport classification_report, confusion_matrix\n",
    "print(classification_report(y_train, y_pred1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.6660833333333334\n",
      "col_0           0     1\n",
      "text_source            \n",
      "0            3798  2201\n",
      "1            1806  4195\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svm = SVC(C=10, gamma=1, kernel='linear')\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "print('Training set score:', svm.score(X_train, y_train))\n",
    "y_pred1 = svm.predict(X_train)\n",
    "print(pd.crosstab(y_train, y_pred1))\n",
    "\n",
    "#print('\\nTest set score:', svm.score(X_test, y_test))\n",
    "#y_pred2 = svm.predict(X_test)\n",
    "#pd.crosstab(y_test, y_pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.68      0.63      0.65      5999\n",
      "          1       0.66      0.70      0.68      6001\n",
      "\n",
      "avg / total       0.67      0.67      0.67     12000\n",
      "\n",
      "\n",
      " Testing set score:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.63      0.65      4001\n",
      "          1       0.65      0.69      0.67      3999\n",
      "\n",
      "avg / total       0.66      0.66      0.66      8000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(classification_report(y_train, y_pred1))\n",
    "print('\\n Testing set score:')\n",
    "y_pred2 = svm.predict(X_test)\n",
    "print(classification_report(y_test, y_pred2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using GridSearchCV from sklearn to find the optimal parameters for C, gamma and kernel from a given set of values to improve our accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "param_grid = {'C':[1,10,100,1000],'gamma':[1,0.1,0.001,0.0001], 'kernel':['linear']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "grid = GridSearchCV(SVC(),param_grid,refit = True, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n",
      "[CV] C=1, gamma=1, kernel=linear .....................................\n",
      "[CV] ............................ C=1, gamma=1, kernel=linear -   7.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    7.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] C=1, gamma=1, kernel=linear .....................................\n",
      "[CV] ............................ C=1, gamma=1, kernel=linear -   3.6s\n",
      "[CV] C=1, gamma=1, kernel=linear .....................................\n",
      "[CV] ............................ C=1, gamma=1, kernel=linear -   4.0s\n",
      "[CV] C=1, gamma=0.1, kernel=linear ...................................\n",
      "[CV] .......................... C=1, gamma=0.1, kernel=linear -   7.0s\n",
      "[CV] C=1, gamma=0.1, kernel=linear ...................................\n",
      "[CV] .......................... C=1, gamma=0.1, kernel=linear -   3.7s\n",
      "[CV] C=1, gamma=0.1, kernel=linear ...................................\n",
      "[CV] .......................... C=1, gamma=0.1, kernel=linear -   4.0s\n",
      "[CV] C=1, gamma=0.001, kernel=linear .................................\n",
      "[CV] ........................ C=1, gamma=0.001, kernel=linear -   6.9s\n",
      "[CV] C=1, gamma=0.001, kernel=linear .................................\n",
      "[CV] ........................ C=1, gamma=0.001, kernel=linear -   3.7s\n",
      "[CV] C=1, gamma=0.001, kernel=linear .................................\n",
      "[CV] ........................ C=1, gamma=0.001, kernel=linear -   4.1s\n",
      "[CV] C=1, gamma=0.0001, kernel=linear ................................\n",
      "[CV] ....................... C=1, gamma=0.0001, kernel=linear -   7.0s\n",
      "[CV] C=1, gamma=0.0001, kernel=linear ................................\n",
      "[CV] ....................... C=1, gamma=0.0001, kernel=linear -   3.8s\n",
      "[CV] C=1, gamma=0.0001, kernel=linear ................................\n",
      "[CV] ....................... C=1, gamma=0.0001, kernel=linear -   4.1s\n",
      "[CV] C=10, gamma=1, kernel=linear ....................................\n",
      "[CV] ........................... C=10, gamma=1, kernel=linear -  12.5s\n",
      "[CV] C=10, gamma=1, kernel=linear ....................................\n",
      "[CV] ........................... C=10, gamma=1, kernel=linear -  40.7s\n",
      "[CV] C=10, gamma=1, kernel=linear ....................................\n",
      "[CV] ........................... C=10, gamma=1, kernel=linear -  39.4s\n",
      "[CV] C=10, gamma=0.1, kernel=linear ..................................\n",
      "[CV] ......................... C=10, gamma=0.1, kernel=linear -  12.4s\n",
      "[CV] C=10, gamma=0.1, kernel=linear ..................................\n",
      "[CV] ......................... C=10, gamma=0.1, kernel=linear -  41.4s\n",
      "[CV] C=10, gamma=0.1, kernel=linear ..................................\n",
      "[CV] ......................... C=10, gamma=0.1, kernel=linear -  38.3s\n",
      "[CV] C=10, gamma=0.001, kernel=linear ................................\n",
      "[CV] ....................... C=10, gamma=0.001, kernel=linear -  12.8s\n",
      "[CV] C=10, gamma=0.001, kernel=linear ................................\n",
      "[CV] ....................... C=10, gamma=0.001, kernel=linear -  41.4s\n",
      "[CV] C=10, gamma=0.001, kernel=linear ................................\n",
      "[CV] ....................... C=10, gamma=0.001, kernel=linear -  38.7s\n",
      "[CV] C=10, gamma=0.0001, kernel=linear ...............................\n",
      "[CV] ...................... C=10, gamma=0.0001, kernel=linear -  12.5s\n",
      "[CV] C=10, gamma=0.0001, kernel=linear ...............................\n",
      "[CV] ...................... C=10, gamma=0.0001, kernel=linear -  41.3s\n",
      "[CV] C=10, gamma=0.0001, kernel=linear ...............................\n",
      "[CV] ...................... C=10, gamma=0.0001, kernel=linear -  38.4s\n",
      "[CV] C=100, gamma=1, kernel=linear ...................................\n",
      "[CV] .......................... C=100, gamma=1, kernel=linear - 1.8min\n",
      "[CV] C=100, gamma=1, kernel=linear ...................................\n",
      "[CV] .......................... C=100, gamma=1, kernel=linear - 2.1min\n",
      "[CV] C=100, gamma=1, kernel=linear ...................................\n",
      "[CV] .......................... C=100, gamma=1, kernel=linear - 4.7min\n",
      "[CV] C=100, gamma=0.1, kernel=linear .................................\n",
      "[CV] ........................ C=100, gamma=0.1, kernel=linear - 1.9min\n",
      "[CV] C=100, gamma=0.1, kernel=linear .................................\n",
      "[CV] ........................ C=100, gamma=0.1, kernel=linear - 2.1min\n",
      "[CV] C=100, gamma=0.1, kernel=linear .................................\n",
      "[CV] ........................ C=100, gamma=0.1, kernel=linear - 4.8min\n",
      "[CV] C=100, gamma=0.001, kernel=linear ...............................\n",
      "[CV] ...................... C=100, gamma=0.001, kernel=linear - 1.8min\n",
      "[CV] C=100, gamma=0.001, kernel=linear ...............................\n",
      "[CV] ...................... C=100, gamma=0.001, kernel=linear - 2.1min\n",
      "[CV] C=100, gamma=0.001, kernel=linear ...............................\n",
      "[CV] ...................... C=100, gamma=0.001, kernel=linear - 4.7min\n",
      "[CV] C=100, gamma=0.0001, kernel=linear ..............................\n",
      "[CV] ..................... C=100, gamma=0.0001, kernel=linear - 2.0min\n",
      "[CV] C=100, gamma=0.0001, kernel=linear ..............................\n",
      "[CV] ..................... C=100, gamma=0.0001, kernel=linear - 2.1min\n",
      "[CV] C=100, gamma=0.0001, kernel=linear ..............................\n",
      "[CV] ..................... C=100, gamma=0.0001, kernel=linear - 4.8min\n",
      "[CV] C=1000, gamma=1, kernel=linear ..................................\n",
      "[CV] ......................... C=1000, gamma=1, kernel=linear - 3.1min\n",
      "[CV] C=1000, gamma=1, kernel=linear ..................................\n",
      "[CV] ......................... C=1000, gamma=1, kernel=linear - 4.0min\n",
      "[CV] C=1000, gamma=1, kernel=linear ..................................\n",
      "[CV] ......................... C=1000, gamma=1, kernel=linear - 2.7min\n",
      "[CV] C=1000, gamma=0.1, kernel=linear ................................\n",
      "[CV] ....................... C=1000, gamma=0.1, kernel=linear - 3.0min\n",
      "[CV] C=1000, gamma=0.1, kernel=linear ................................\n",
      "[CV] ....................... C=1000, gamma=0.1, kernel=linear - 4.1min\n",
      "[CV] C=1000, gamma=0.1, kernel=linear ................................\n",
      "[CV] ....................... C=1000, gamma=0.1, kernel=linear - 2.7min\n",
      "[CV] C=1000, gamma=0.001, kernel=linear ..............................\n",
      "[CV] ..................... C=1000, gamma=0.001, kernel=linear - 3.0min\n",
      "[CV] C=1000, gamma=0.001, kernel=linear ..............................\n",
      "[CV] ..................... C=1000, gamma=0.001, kernel=linear - 3.9min\n",
      "[CV] C=1000, gamma=0.001, kernel=linear ..............................\n",
      "[CV] ..................... C=1000, gamma=0.001, kernel=linear - 2.6min\n",
      "[CV] C=1000, gamma=0.0001, kernel=linear .............................\n",
      "[CV] .................... C=1000, gamma=0.0001, kernel=linear - 3.0min\n",
      "[CV] C=1000, gamma=0.0001, kernel=linear .............................\n",
      "[CV] .................... C=1000, gamma=0.0001, kernel=linear - 3.9min\n",
      "[CV] C=1000, gamma=0.0001, kernel=linear .............................\n",
      "[CV] .................... C=1000, gamma=0.0001, kernel=linear - 2.7min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  48 out of  48 | elapsed: 81.0min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'C': [1, 10, 100, 1000], 'gamma': [1, 0.1, 0.001, 0.0001], 'kernel': ['linear']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring=None, verbose=2)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 10, 'gamma': 1, 'kernel': 'linear'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.51      0.52      0.51      5999\n",
      "          1       0.51      0.50      0.51      6001\n",
      "\n",
      "avg / total       0.51      0.51      0.51     12000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#This was attempt on subsection of the dataset to reduce load but the parameter found did not improve prediction\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "y_pred1 = grid.predict(X_train)\n",
    "print(classification_report(y_train, y_pred1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.65      0.65      0.65       204\n",
      "          1       0.64      0.64      0.64       196\n",
      "\n",
      "avg / total       0.65      0.65      0.65       400\n",
      "\n",
      "col_0          0    1\n",
      "text_source          \n",
      "0            132   72\n",
      "1             70  126\n"
     ]
    }
   ],
   "source": [
    "y_pred1 = grid.predict(X_test)\n",
    "print(classification_report(y_test, y_pred1))\n",
    "print(pd.crosstab(y_test, y_pred1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating clusters\n",
    "### K-Mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparing k-means clusters against the data:\n",
      "text_source     0     1\n",
      "row_0                  \n",
      "0            3846  4301\n",
      "1            2153  1700\n",
      "Comparing k-means clusters against the data:\n",
      "text_source     0     1\n",
      "row_0                  \n",
      "0            1052  1005\n",
      "1            4947  4996\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Normalize the data.\n",
    "X_train_norm = normalize(X_train)\n",
    "X_test_norm = normalize(X_test)\n",
    "\n",
    "# Reduce it to two components.\n",
    "X_train_pca = PCA(n_components=0.95).fit_transform(X_train_norm)\n",
    "X_test_pca = PCA(n_components=0.95).fit_transform(X_test_norm)\n",
    "\n",
    "KMean1 = KMeans(n_clusters=2, random_state=42)\n",
    "KMean2 = KMeans(n_clusters=2, random_state=42)\n",
    "\n",
    "KMean1.fit(X_train_pca)\n",
    "KMean2.fit(X_train)\n",
    "\n",
    "y_pred1 = KMean1.predict(X_train_pca)\n",
    "y_pred2 = KMean2.predict(X_train)\n",
    "\n",
    "# Check the solution against the data.\n",
    "print('Comparing k-means clusters against the data:')\n",
    "print(pd.crosstab(y_pred1, y_train))\n",
    "print('Comparing k-means clusters against the data:')\n",
    "print(pd.crosstab(y_pred2, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparing k-means clusters against the data:\n",
      "Comparing k-means clusters against the data:\n",
      "text_source     0     1\n",
      "row_0                  \n",
      "0             656   699\n",
      "1            3345  3300\n"
     ]
    }
   ],
   "source": [
    "#y_pred1 = KMean1.predict(X_test_pca)\n",
    "y_pred2 = KMean2.predict(X_test)\n",
    "\n",
    "print('Comparing k-means clusters against the data:')\n",
    "#print(pd.crosstab(y_pred1, y_test))\n",
    "print('Comparing k-means clusters against the data:')\n",
    "print(pd.crosstab(y_pred2, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# minibatchkmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "minibatchkmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.8171666666666667\n",
      "\n",
      "Test set score: 0.78925\n"
     ]
    }
   ],
   "source": [
    "from sklearn import ensemble\n",
    "\n",
    "clf = ensemble.GradientBoostingClassifier()\n",
    "train = clf.fit(X_train, y_train)\n",
    "\n",
    "print('Training set score:', clf.score(X_train, y_train))\n",
    "print('\\nTest set score:', clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
